{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation\n",
    "\n",
    "RAG combines search (retrieval) with AI text generation. First retrieve relevant documents, then use them to generate informed responses.\n",
    "\n",
    "![images/llm_2_rag_basic.png](images/llm_2_rag_basic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Weaviate\n",
    "\n",
    "Connect to a Weaviate instance with third party credentials as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh credentials & load the Weaviate IP\n",
    "from helpers import update_creds\n",
    "\n",
    "AWS_ACCESS_KEY, AWS_SECRET_KEY, AWS_SESSION_TOKEN = update_creds()\n",
    "\n",
    "%store -r WEAVIATE_IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    WEAVIATE_IP,\n",
    "    headers = {\n",
    "        \"X-AWS-Access-Key\": AWS_ACCESS_KEY,\n",
    "        \"X-AWS-Secret-Key\": AWS_SECRET_KEY,\n",
    "        \"X-AWS-Session-Token\": AWS_SESSION_TOKEN,\n",
    "    }        \n",
    ")\n",
    "\n",
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with (R) - Retrieval\n",
    "\n",
    "First step: retrieve relevant documents using search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = client.collections.use(\"FinancialArticles\")\n",
    "\n",
    "response = articles.query.near_text(\n",
    "    query=\"cloud revenue\",\n",
    "    limit=5,\n",
    "    target_vector=\"title\",\n",
    ")\n",
    "\n",
    "for item in response.objects:\n",
    "    print(item.properties[\"article_title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add (AG) - augmented generation - to make full RAG\n",
    "\n",
    "Second step: use retrieved documents to generate informed responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Prompt\n",
    "\n",
    "> Generate a response per **retrieved** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add some colour to our lives :)\n",
    "BLUE   = \"\\033[94m\"\n",
    "PURPLE = \"\\033[95m\"\n",
    "RESET  = \"\\033[0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.generate import GenerativeConfig\n",
    "\n",
    "articles = client.collections.use(\"FinancialArticles\")\n",
    "\n",
    "response = articles.generate.near_text(\n",
    "    query=\"cloud revenue\",\n",
    "    limit=5,\n",
    "    target_vector=\"title\",\n",
    "    generative_provider=GenerativeConfig.openai(\n",
    "        model=\"gpt-4o-mini\",\n",
    "    ),\n",
    "    single_prompt=\"Summarize this article to a sentence or two: {article}\"\n",
    ")\n",
    "\n",
    "for item in response.objects:\n",
    "    print(f\"{BLUE}=== Source ===\")\n",
    "    print(item.properties[\"article_title\"])\n",
    "\n",
    "    print(f\"{PURPLE}=== Generated Response ===\")\n",
    "    print(item.generative.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouped Task\n",
    "\n",
    "Generate one response using all retrieved documents together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = articles.generate.near_text(\n",
    "    query=\"cloud revenue\",\n",
    "    limit=5,\n",
    "    target_vector=\"title\",\n",
    "    generative_provider=GenerativeConfig.openai(model=\"gpt-4o-mini\"),\n",
    "    grouped_task=\"Explain top 3 or so common trends or overall learnings in these articles. Please only use the provided content.\"\n",
    ")\n",
    "\n",
    "print(f\"{PURPLE}=== Generated Response ===\")\n",
    "print(response.generative.text)\n",
    "\n",
    "print(f\"{BLUE}=== Source ===\")\n",
    "for item in response.objects:\n",
    "    print(item.properties[\"article_title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![images/llm_3_rag_weaviate.png](images/llm_3_rag_weaviate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify which properties to use for grouped task\n",
    "\n",
    "Control which document fields the AI uses for generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = articles.generate.near_text(\n",
    "    query=\"artificial intelligence\",\n",
    "    limit=50,\n",
    "    target_vector=\"title\",\n",
    "    grouped_task=\"What are the top 3 most common types of articles, based on these titles? Please only use the provided content.\",\n",
    "    grouped_properties=[\"article_title\"],\n",
    "\n",
    "    generative_provider=GenerativeConfig.openai(\n",
    "        model=\"gpt-4o-mini\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"{PURPLE}=== Generated Response ===\")\n",
    "print(response.generative.text)\n",
    "\n",
    "print(f\"{BLUE}=== Source ===\")\n",
    "for item in response.objects:\n",
    "    print(item.properties[\"article_title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set default Generative model\n",
    "\n",
    "Configure a default model to avoid specifying it each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Reconfigure\n",
    "\n",
    "articles.config.update(\n",
    "    generative_config=Reconfigure.Generative.openai(\n",
    "        model=\"gpt-4o-mini\"  # Update the generative model\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try generative query without specifying the model (uses default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = articles.generate.near_text(\n",
    "    query=\"cryptocurrency regulation\",\n",
    "    limit=5,\n",
    "    target_vector=\"title\",\n",
    "    grouped_task=\"Briefly, what topics are covered in these articles? Please only use the provided content.\",\n",
    ")\n",
    "\n",
    "print(f\"{PURPLE}=== Generated Response ===\")\n",
    "print(response.generative.text)\n",
    "\n",
    "print(f\"{BLUE}=== Source ===\")\n",
    "for item in response.objects:\n",
    "    print(item.properties[\"article_title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close the client\n",
    "\n",
    "Always close your connection when finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
