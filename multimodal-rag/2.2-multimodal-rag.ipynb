{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6861ab3-dffd-4da4-a819-b090b8ae756e",
   "metadata": {},
   "source": [
    "### Load chunks as we did before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54c46a-e478-46ea-9828-1505c9cfef26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:54:37.180356Z",
     "iopub.status.busy": "2025-09-04T14:54:37.180128Z",
     "iopub.status.idle": "2025-09-04T14:54:38.744294Z",
     "shell.execute_reply": "2025-09-04T14:54:38.743491Z",
     "shell.execute_reply.started": "2025-09-04T14:54:37.180335Z"
    }
   },
   "outputs": [],
   "source": [
    "from chonkie import SemanticChunker\n",
    "from pathlib import Path\n",
    "\n",
    "md_filepath = Path(\"data/parsed/hai_ai-index-report-2025_chapter2_excerpts-parsed-w-imgs.md\")\n",
    "md_txt = md_filepath.read_text()\n",
    "\n",
    "chunker = SemanticChunker(\n",
    "    embedding_model=\"minishlab/potion-base-8M\",  # Default model\n",
    "    threshold=0.5,                               # Similarity threshold (0-1) or (1-100) or \"auto\"\n",
    "    chunk_size=2048,                              # Maximum tokens per chunk\n",
    "    min_sentences=1                              # Initial sentences per chunk\n",
    ")\n",
    "chunk_texts = chunker.chunk(md_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a2a8a4",
   "metadata": {},
   "source": [
    "### Set up Weaviate Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b22f3-07d4-4f7c-91c3-234ceb94511e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T16:17:19.043659Z",
     "iopub.status.busy": "2025-09-04T16:17:19.043354Z",
     "iopub.status.idle": "2025-09-04T16:17:19.059810Z",
     "shell.execute_reply": "2025-09-04T16:17:19.059098Z",
     "shell.execute_reply.started": "2025-09-04T16:17:19.043637Z"
    }
   },
   "outputs": [],
   "source": [
    "from helpers import update_creds\n",
    "\n",
    "AWS_ACCESS_KEY, AWS_SECRET_KEY, AWS_SESSION_TOKEN = update_creds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22af250e-be00-421a-948c-3daeda7e3b19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T16:17:20.600181Z",
     "iopub.status.busy": "2025-09-04T16:17:20.599677Z",
     "iopub.status.idle": "2025-09-04T16:17:20.686746Z",
     "shell.execute_reply": "2025-09-04T16:17:20.685956Z",
     "shell.execute_reply.started": "2025-09-04T16:17:20.600147Z"
    }
   },
   "outputs": [],
   "source": [
    "import weaviate\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    WEAVIATE_IP,\n",
    "    headers = {\n",
    "        \"X-AWS-Access-Key\": AWS_ACCESS_KEY,\n",
    "        \"X-AWS-Secret-Key\": AWS_SECRET_KEY,\n",
    "        \"X-AWS-Session-Token\": AWS_SESSION_TOKEN,\n",
    "    }\n",
    ")\n",
    "\n",
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842550b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T16:17:22.589947Z",
     "iopub.status.busy": "2025-09-04T16:17:22.589431Z",
     "iopub.status.idle": "2025-09-04T16:17:22.602223Z",
     "shell.execute_reply": "2025-09-04T16:17:22.601436Z",
     "shell.execute_reply.started": "2025-09-04T16:17:22.589904Z"
    }
   },
   "outputs": [],
   "source": [
    "client.collections.delete(\"Chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e202bae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T16:17:23.571902Z",
     "iopub.status.busy": "2025-09-04T16:17:23.571605Z",
     "iopub.status.idle": "2025-09-04T16:17:23.744456Z",
     "shell.execute_reply": "2025-09-04T16:17:23.743658Z",
     "shell.execute_reply.started": "2025-09-04T16:17:23.571881Z"
    }
   },
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Property, DataType, Configure, Tokenization\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"Chunks\",\n",
    "    properties=[\n",
    "        Property(\n",
    "            name=\"document_title\",\n",
    "            data_type=DataType.TEXT,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"chunk\",\n",
    "            data_type=DataType.TEXT,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"chunk_number\",\n",
    "            data_type=DataType.INT,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"filename\",\n",
    "            data_type=DataType.TEXT,\n",
    "            tokenization=Tokenization.FIELD\n",
    "        ),\n",
    "    ],\n",
    "    vector_config=[\n",
    "        Configure.Vectors.text2vec_aws(\n",
    "            name=\"default\",\n",
    "            source_properties=[\"document_title\", \"chunk\"],\n",
    "            region=\"us-west-2\",\n",
    "            service=\"bedrock\",\n",
    "            model=\"amazon.titan-embed-text-v2:0\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e2f9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T16:17:24.735497Z",
     "iopub.status.busy": "2025-09-04T16:17:24.735204Z",
     "iopub.status.idle": "2025-09-04T16:17:24.740484Z",
     "shell.execute_reply": "2025-09-04T16:17:24.739337Z",
     "shell.execute_reply.started": "2025-09-04T16:17:24.735474Z"
    }
   },
   "outputs": [],
   "source": [
    "chunks = client.collections.use(\"Chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34f3bad",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee53991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T16:17:25.946999Z",
     "iopub.status.busy": "2025-09-04T16:17:25.946725Z",
     "iopub.status.idle": "2025-09-04T16:17:27.760130Z",
     "shell.execute_reply": "2025-09-04T16:17:27.759319Z",
     "shell.execute_reply.started": "2025-09-04T16:17:25.946980Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with chunks.batch.fixed_size(batch_size=100) as batch:\n",
    "    for i, chunk_text in tqdm(enumerate(chunk_texts)):\n",
    "        obj = {\n",
    "            \"document_title\": \"HAI AI Index Report 2025\",\n",
    "            \"filename\": \"data/pdfs/hai_ai-index-report-2025_chapter2_excerpts.pdf\",\n",
    "            \"chunk\": chunk_text.text,\n",
    "            \"chunk_number\": i + 1,\n",
    "        }\n",
    "\n",
    "        # Add object to batch for import with (batch.add_object())\n",
    "        # ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ed8bc9",
   "metadata": {},
   "source": [
    "### RAG queries\n",
    "\n",
    "In this scenario, let's:\n",
    "\n",
    "- Retrieve text chunks\n",
    "- Get images referred to in the text\n",
    "- Convert the images to base64\n",
    "- Send (retrieved text + images + prompt) to LLM for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae8dd66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T16:17:50.920122Z",
     "iopub.status.busy": "2025-09-04T16:17:50.919778Z",
     "iopub.status.idle": "2025-09-04T16:17:51.009371Z",
     "shell.execute_reply": "2025-09-04T16:17:51.008478Z",
     "shell.execute_reply.started": "2025-09-04T16:17:50.920098Z"
    }
   },
   "outputs": [],
   "source": [
    "response = chunks.query.hybrid(\n",
    "    query=\"Recent advances in RAG\",\n",
    "    limit=10\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(f\"\\n\" + \"=\" * 40)\n",
    "    print(o.properties[\"chunk\"][:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a729583",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T16:17:51.982344Z",
     "iopub.status.busy": "2025-09-04T16:17:51.982064Z",
     "iopub.status.idle": "2025-09-04T16:17:51.986003Z",
     "shell.execute_reply": "2025-09-04T16:17:51.985095Z",
     "shell.execute_reply.started": "2025-09-04T16:17:51.982324Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_image_paths(text):\n",
    "    \"\"\"Extract image paths from markdown-style image references.\"\"\"\n",
    "    pattern = r'!\\[.*?\\]\\((.*?)\\)'\n",
    "    return re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d036efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T16:17:52.555583Z",
     "iopub.status.busy": "2025-09-04T16:17:52.555303Z",
     "iopub.status.idle": "2025-09-04T16:17:52.559524Z",
     "shell.execute_reply": "2025-09-04T16:17:52.558780Z",
     "shell.execute_reply.started": "2025-09-04T16:17:52.555563Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_image_base64s(image_paths, base_path=None):\n",
    "    import base64\n",
    "    base64_images = []\n",
    "    for img_path in image_paths:\n",
    "        full_path = Path(base_path) / img_path if base_path else Path(img_path)\n",
    "        image_bytes = full_path.read_bytes()\n",
    "        base64_string = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "        base64_images.append(base64_string)\n",
    "\n",
    "    return base64_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430397bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T16:17:53.151521Z",
     "iopub.status.busy": "2025-09-04T16:17:53.151239Z",
     "iopub.status.idle": "2025-09-04T16:17:53.160998Z",
     "shell.execute_reply": "2025-09-04T16:17:53.160202Z",
     "shell.execute_reply.started": "2025-09-04T16:17:53.151501Z"
    }
   },
   "outputs": [],
   "source": [
    "all_chunks = \"\"\n",
    "all_images = []\n",
    "\n",
    "for o in response.objects:\n",
    "    chunk_text = o.properties[\"chunk\"]\n",
    "    image_paths = extract_image_paths(chunk_text)\n",
    "    print(f\"Adding image paths: {image_paths}\")\n",
    "    all_images.extend(get_image_base64s(image_paths, base_path=\"data/parsed\"))\n",
    "\n",
    "    all_chunks += \"\\n\\n\" + chunk_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93da885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T16:19:59.520194Z",
     "iopub.status.busy": "2025-09-04T16:19:59.519766Z",
     "iopub.status.idle": "2025-09-04T16:19:59.524473Z",
     "shell.execute_reply": "2025-09-04T16:19:59.523664Z",
     "shell.execute_reply.started": "2025-09-04T16:19:59.520169Z"
    }
   },
   "outputs": [],
   "source": [
    "message_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": []\n",
    "    }\n",
    "]\n",
    "\n",
    "for img in all_images:\n",
    "    content = {\n",
    "        \"image\": {\n",
    "            \"format\": \"png\",\n",
    "            \"source\": {\n",
    "                \"bytes\": img\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "    message_list[0][\"content\"].append(content)\n",
    "\n",
    "task_text = \"\"\"\n",
    "What does this text tell us about the latest developments in RAG?\n",
    "\n",
    "Describe the details from the figures as well, if necessary.\n",
    "\"\"\" + \"\\n\\n\" + all_chunks\n",
    "message_list[0][\"content\"].append({\"text\": task_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b0c9d7-352c-4ea9-ba2a-8e0eac890adf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T16:20:08.746277Z",
     "iopub.status.busy": "2025-09-04T16:20:08.745986Z",
     "iopub.status.idle": "2025-09-04T16:20:13.468754Z",
     "shell.execute_reply": "2025-09-04T16:20:13.468212Z",
     "shell.execute_reply.started": "2025-09-04T16:20:08.746256Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "client = boto3.client(\n",
    "    \"bedrock-runtime\",\n",
    "    region_name=\"us-west-2\",\n",
    ")\n",
    "\n",
    "# MODEL_ID = \"us.amazon.nova-lite-v1:0\"\n",
    "MODEL_ID = \"us.amazon.nova-pro-v1:0\"\n",
    "\n",
    "# Define your system prompt(s).\n",
    "system_list = [    {\n",
    "        \"text\": \"You are an expert. Read the provided text and content of these images and answer the questions thoughtfully but succinctly if possible.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Configure the inference parameters.\n",
    "inf_params = {\"maxTokens\": 300, \"topP\": 0.1, \"topK\": 20, \"temperature\": 0.3}\n",
    "\n",
    "native_request = {\n",
    "    \"schemaVersion\": \"messages-v1\",\n",
    "    \"messages\": message_list,\n",
    "    \"system\": system_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "# Invoke the model and extract the response body.\n",
    "response = client.invoke_model(modelId=MODEL_ID, body=json.dumps(native_request))\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Print the text content for easy readability.\n",
    "content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d67fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
