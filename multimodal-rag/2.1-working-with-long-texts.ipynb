{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34fbb67f",
   "metadata": {},
   "source": [
    "## PDF Text extraction & chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8693ef",
   "metadata": {},
   "source": [
    "### PDF to text\n",
    "\n",
    "PDFs contain rich formatting that needs to be extracted as clean text for AI processing. \n",
    "\n",
    "Modern libraries like `docling` can preserve document structure while converting to text format, making the text easier to process while maintaining semantic relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7edd6c",
   "metadata": {},
   "source": [
    "Inspect a PDF converted with `docling`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9dd1ca",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1756203792603,
    "lastExecutedByKernel": "fe7640a5-8f98-4365-917b-a2fa71df5513",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "md_filepath = Path(\"data/parsed/howto-free-threading-python-parsed-text.md\")\nmd_txt = md_filepath.read_text()\nprint(md_txt[:2000])",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "md_filepath = Path(\"data/parsed/amazon-2025-08-8k-excerpts-parsed-text.md\")\n",
    "md_txt = md_filepath.read_text()\n",
    "print(md_txt[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_example = md_txt.split(\"## Consolidated Statements of Operations\")[1]\n",
    "print(table_example[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b62b17",
   "metadata": {},
   "source": [
    "### Chunking\n",
    "\n",
    "Raw text from PDFs is often too long for AI models to process effectively. Chunking breaks documents into smaller, manageable pieces while preserving context. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3f956e",
   "metadata": {},
   "source": [
    "#### Chunk by text length\n",
    "\n",
    "Fixed-length chunks are simple but can break sentences or paragraphs mid-thought. This approach is fast and predictable, making it suitable for initial processing or when document structure is uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6773b88",
   "metadata": {},
   "source": [
    "![images/chunking_why.png](images/chunking_why.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99973c13",
   "metadata": {},
   "source": [
    "Different chunking strategies serve different use cases. \n",
    "\n",
    "![images/chunking_methods.png](images/chunking_methods.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c3c26",
   "metadata": {},
   "source": [
    "Let's try a few options:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddfa414",
   "metadata": {},
   "source": [
    "#### Chunk by text length with overlap\n",
    "\n",
    "Overlapping chunks help maintain context across boundaries. \n",
    "\n",
    "When a concept spans multiple chunks, the overlap helps to capture it. This is especially important for maintaining semantic coherence in search and retrieval systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3329d7",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1756203792650,
    "lastExecutedByKernel": "fe7640a5-8f98-4365-917b-a2fa71df5513",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "def get_chunks_by_length_with_overlap(src_text: str, chunk_length: int = 500, overlap: int = 100) -> list[str]:\n    \"\"\"\n    Split text into chunks of approximately `chunk_length` characters.\n    \"\"\"\n    chunks = []\n    for i in range(0, len(src_text), chunk_length):\n        chunks.append(src_text[i:i + chunk_length + overlap])\n    return chunks"
   },
   "outputs": [],
   "source": [
    "def get_chunks_by_length_with_overlap(src_text: str, chunk_length: int = 500, overlap: int = 100) -> list[str]:\n",
    "    \"\"\"\n",
    "    Split text into chunks of approximately `chunk_length` characters.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for i in range(0, len(src_text), chunk_length):\n",
    "        chunks.append(src_text[i:i + chunk_length + overlap])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc39a6c",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1756203792700,
    "lastExecutedByKernel": "fe7640a5-8f98-4365-917b-a2fa71df5513",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "chunks = get_chunks_by_length_with_overlap(md_txt)\ndisplay(chunks[:5])\nprint(len(chunks[0]))",
    "outputsMetadata": {
     "1": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# STUDENT TODO\n",
    "# Chunk `md_text_1` with `get_chunks_by_length_with_overlap`\n",
    "# Inspect the first 5 or so chunks\n",
    "# START_SOLUTION\n",
    "chunks = get_chunks_by_length_with_overlap(md_txt)\n",
    "\n",
    "for chunk in chunks[:5]:\n",
    "    print(\"\\n\\nChunk: \" + \"=\" * 10 + f\"\\n{chunk}\")\n",
    "# END_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b694e768",
   "metadata": {},
   "source": [
    "#### Chunk using markers\n",
    "\n",
    "Using document markers (like headers) creates chunks that respect natural document boundaries. \n",
    "\n",
    "This approach preserves semantic structure and is ideal for documents with clear hierarchical organization like reports, manuals, or academic papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35daea7d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 46,
    "lastExecutedAt": 1756203792746,
    "lastExecutedByKernel": "fe7640a5-8f98-4365-917b-a2fa71df5513",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "def get_chunks_using_markers(src_text: str) -> list[str]:\n    \"\"\"\n    Split the source text into chunks using markers.\n    \"\"\"\n    marker = \"\\n##\"\n\n    # Split by marker and reconstruct with markers (except first chunk)\n    parts = src_text.split(marker)\n    chunks = []\n\n    # Add first chunk if it exists and isn't empty\n    if parts[0].strip():\n        chunks.append(parts[0].strip())\n\n    # Add remaining chunks with markers reattached\n    for part in parts[1:]:\n        if part.strip():\n            chunks.append(marker + part.strip())\n\n    return chunks"
   },
   "outputs": [],
   "source": [
    "def get_chunks_using_markers(src_text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Split the source text into chunks using markers.\n",
    "    \"\"\"\n",
    "    marker = \"\\n##\"\n",
    "\n",
    "    # Split by marker and reconstruct with markers (except first chunk)\n",
    "    parts = src_text.split(marker)\n",
    "    chunks = []\n",
    "\n",
    "    # Add first chunk if it exists and isn't empty\n",
    "    if parts[0].strip():\n",
    "        chunks.append(parts[0].strip())\n",
    "\n",
    "    # Add remaining chunks with markers reattached\n",
    "    for part in parts[1:]:\n",
    "        if part.strip():\n",
    "            chunks.append(marker + part.strip())\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd11080",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1756203792796,
    "lastExecutedByKernel": "fe7640a5-8f98-4365-917b-a2fa71df5513",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "md_file_1 = Path(\"data/parsed/howto-free-threading-python-parsed-text.md\")\nmd_text_1 = md_file_1.read_text(encoding=\"utf-8\")\nchunks = get_chunks_using_markers(md_text_1)\n\nfor chunk in chunks[:5]:\n    print(\"\\n\\nChunk: \" + \"=\" * 10 + f\"\\n{chunk}\")",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "md_file_1 = Path(\"data/parsed/amazon-2025-08-8k-excerpts-parsed-text.md\")\n",
    "md_text_1 = md_file_1.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# STUDENT TODO\n",
    "# Chunk `md_text_1` with `get_chunks_using_markers`\n",
    "# Inspect the first 5 or so chunks\n",
    "# START_SOLUTION\n",
    "chunks = get_chunks_using_markers(md_text_1)\n",
    "\n",
    "for chunk in chunks[:5]:\n",
    "    print(\"\\n\\nChunk: \" + \"=\" * 10 + f\"\\n{chunk}\")\n",
    "# END_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0841b2",
   "metadata": {},
   "source": [
    "### Choosing the right strategy\n",
    "\n",
    "The best chunking strategy depends on your use case. \n",
    "\n",
    "Marker-based chunking excels with structured documents as you saw. But in some cases, it may not work as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251fc27",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1756203792843,
    "lastExecutedByKernel": "fe7640a5-8f98-4365-917b-a2fa71df5513",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "md_file_2 = Path(\"data/parsed/hai_ai-index-report-2025_chapter2_excerpts-parsed-text.md\")\nmd_text_2 = md_file_2.read_text(encoding=\"utf-8\")\nchunks = get_chunks_using_markers(md_text_2)\n\nfor chunk in chunks[:5]:\n    print(\"\\n\\nChunk:\" + \"=\" * 10 + f\"\\n{chunk}\")",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "md_file_2 = Path(\"data/parsed/hai_ai-index-report-2025_chapter2_excerpts-parsed-text.md\")\n",
    "md_text_2 = md_file_2.read_text(encoding=\"utf-8\")\n",
    "\n",
    "chunks = get_chunks_using_markers(md_text_2)\n",
    "\n",
    "for chunk in chunks[:5]:\n",
    "    print(\"\\n\\nChunk:\" + \"=\" * 10 + f\"\\n{chunk[:50]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96380962",
   "metadata": {},
   "source": [
    "Here, the page headers are mistakenly interpreted as headings, which confuses our structure. \n",
    "\n",
    "In general, the best chunking strategy for you will depend on your specific set of circumstances. But a fixed-length chunking strategy with overlap is a good default choice."
   ]
  }
 ],
 "metadata": {
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
