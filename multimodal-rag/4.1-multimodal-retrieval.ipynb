{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c4a081d",
   "metadata": {},
   "source": [
    "## Working with PDFs with images\n",
    "\n",
    "PDFs contain more than rich formatting - they have images!\n",
    "\n",
    "Run the cells below to convert PDF data to images (this should take about a minute). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a0028a-e09e-4836-a3b1-9f0bdff89bef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:41:06.497562Z",
     "iopub.status.busy": "2025-09-04T14:41:06.497071Z",
     "iopub.status.idle": "2025-09-04T14:41:06.589081Z",
     "shell.execute_reply": "2025-09-04T14:41:06.588355Z",
     "shell.execute_reply.started": "2025-09-04T14:41:06.497531Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import pymupdf\n",
    "except ImportError:\n",
    "    %pip install -Uqq pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d263ecf2-ee73-443b-9a7f-51e446b4c87d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:41:12.200560Z",
     "iopub.status.busy": "2025-09-04T14:41:12.197625Z",
     "iopub.status.idle": "2025-09-04T14:41:13.764648Z",
     "shell.execute_reply": "2025-09-04T14:41:13.763988Z",
     "shell.execute_reply.started": "2025-09-04T14:41:12.200524Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python pdf_to_img.py hai*.pdf\n",
    "echo \"Images extracted from AI report PDF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c46a0b-56dd-44bd-a331-dc693b0625d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:41:15.447219Z",
     "iopub.status.busy": "2025-09-04T14:41:15.446936Z",
     "iopub.status.idle": "2025-09-04T14:41:16.687254Z",
     "shell.execute_reply": "2025-09-04T14:41:16.686569Z",
     "shell.execute_reply.started": "2025-09-04T14:41:15.447197Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "images = [\n",
    "    f\"data/imgs/hai_ai-index-report-2025_chapter2_excerpts_1_of_8.jpg\",\n",
    "    f\"data/imgs/hai_ai-index-report-2025_chapter2_excerpts_4_of_8.jpg\",\n",
    "    f\"data/imgs/hai_ai-index-report-2025_chapter2_excerpts_5_of_8.jpg\"   \n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 40))\n",
    "\n",
    "for i, img_path in enumerate(images):\n",
    "    img = Image.open(img_path)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ce690",
   "metadata": {},
   "source": [
    "How do we work with these for RAG?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d2d4de",
   "metadata": {},
   "source": [
    "### Approach 1 - Extract text and images separately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c0287c",
   "metadata": {},
   "source": [
    "Some libraries (like `docling`) can extract text and images from PDFs, and convert them into Markdown files.\n",
    "\n",
    "Here, we've pre-converted this PDF into markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e8a60c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:41:17.997843Z",
     "iopub.status.busy": "2025-09-04T14:41:17.997486Z",
     "iopub.status.idle": "2025-09-04T14:41:18.002970Z",
     "shell.execute_reply": "2025-09-04T14:41:18.002008Z",
     "shell.execute_reply.started": "2025-09-04T14:41:17.997820Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "md_filepath = Path(\"data/parsed/hai_ai-index-report-2025_chapter2_excerpts-parsed-w-imgs.md\")\n",
    "md_txt = md_filepath.read_text()\n",
    "print(md_txt[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0297db",
   "metadata": {},
   "source": [
    "#### Chunking text files with images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee9281",
   "metadata": {},
   "source": [
    "More complex than just text, since we need to handle images as well.\n",
    "\n",
    "- Must include entire image string in the chunk\n",
    "- When vectorizing, optionally include base64 of image\n",
    "    - Your embedding model must be multimodal\n",
    "\n",
    "Chunking becomes more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd48bb25",
   "metadata": {},
   "source": [
    "One method: try a specialized library like `chonkie` to handle this\n",
    "\n",
    "Chonkie offers a variety of chunking strategies:\n",
    "\n",
    "<img src=\"images/chonkie_methods.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeea62c",
   "metadata": {},
   "source": [
    "There isn't going to be a \"one size fits all\" solution for chunking PDFs with images. But these libraries can help you get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daef5ae",
   "metadata": {},
   "source": [
    "Let's try a couple of different approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190eeb69-2b2e-446a-b1e0-84cb7fc025cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:41:24.444598Z",
     "iopub.status.busy": "2025-09-04T14:41:24.444289Z",
     "iopub.status.idle": "2025-09-04T14:41:27.179348Z",
     "shell.execute_reply": "2025-09-04T14:41:27.178302Z",
     "shell.execute_reply.started": "2025-09-04T14:41:24.444572Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -Uqq \"chonkie[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb5c64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:41:36.028612Z",
     "iopub.status.busy": "2025-09-04T14:41:36.028292Z",
     "iopub.status.idle": "2025-09-04T14:41:36.657653Z",
     "shell.execute_reply": "2025-09-04T14:41:36.656505Z",
     "shell.execute_reply.started": "2025-09-04T14:41:36.028587Z"
    }
   },
   "outputs": [],
   "source": [
    "from chonkie import RecursiveChunker\n",
    "\n",
    "# Initialize the recursive chunker to chunk Markdown\n",
    "chunker = RecursiveChunker.from_recipe(\"markdown\", lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d61fca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:41:37.818415Z",
     "iopub.status.busy": "2025-09-04T14:41:37.818106Z",
     "iopub.status.idle": "2025-09-04T14:41:37.822833Z",
     "shell.execute_reply": "2025-09-04T14:41:37.821675Z",
     "shell.execute_reply.started": "2025-09-04T14:41:37.818392Z"
    }
   },
   "outputs": [],
   "source": [
    "chunk_texts = chunker.chunk(md_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8d48b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:41:40.648442Z",
     "iopub.status.busy": "2025-09-04T14:41:40.647875Z",
     "iopub.status.idle": "2025-09-04T14:41:40.654328Z",
     "shell.execute_reply": "2025-09-04T14:41:40.653381Z",
     "shell.execute_reply.started": "2025-09-04T14:41:40.648417Z"
    }
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "for chunk in chunk_texts[:5]:\n",
    "    print(f\"\\n\" + \"=\" * 40)\n",
    "    print(f\"Token count: {chunk.token_count}\")\n",
    "    print(f\"Chunk text:\")\n",
    "    wrapped_text = textwrap.fill(chunk.text[:500]+\"...\", width=80)\n",
    "    print(textwrap.indent(wrapped_text, \"    \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991dde5e",
   "metadata": {},
   "source": [
    "Let's try a \"semantic\" chunker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60d639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:42:04.931242Z",
     "iopub.status.busy": "2025-09-04T14:42:04.930864Z",
     "iopub.status.idle": "2025-09-04T14:42:06.903634Z",
     "shell.execute_reply": "2025-09-04T14:42:06.902619Z",
     "shell.execute_reply.started": "2025-09-04T14:42:04.931217Z"
    }
   },
   "outputs": [],
   "source": [
    "from chonkie import SemanticChunker\n",
    "\n",
    "# Basic initialization with default parameters\n",
    "chunker = SemanticChunker(\n",
    "    embedding_model=\"minishlab/potion-base-8M\",  # Default model\n",
    "    threshold=0.5,                               # Similarity threshold (0-1) or (1-100) or \"auto\"\n",
    "    chunk_size=2048,                              # Maximum tokens per chunk\n",
    "    min_sentences=1                              # Initial sentences per chunk\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aed757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:42:08.455062Z",
     "iopub.status.busy": "2025-09-04T14:42:08.454718Z",
     "iopub.status.idle": "2025-09-04T14:42:08.569768Z",
     "shell.execute_reply": "2025-09-04T14:42:08.569011Z",
     "shell.execute_reply.started": "2025-09-04T14:42:08.455035Z"
    }
   },
   "outputs": [],
   "source": [
    "# Chunk text into `chunk_texts` as we've done before\n",
    "# ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7042aec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T14:42:39.006267Z",
     "iopub.status.busy": "2025-09-04T14:42:39.005972Z",
     "iopub.status.idle": "2025-09-04T14:42:39.012188Z",
     "shell.execute_reply": "2025-09-04T14:42:39.011221Z",
     "shell.execute_reply.started": "2025-09-04T14:42:39.006245Z"
    }
   },
   "outputs": [],
   "source": [
    "for chunk in chunk_texts[:5]:\n",
    "    print(f\"\\n\" + \"=\" * 40)\n",
    "    print(f\"Token count: {chunk.token_count}\")\n",
    "    print(f\"Chunk text:\")\n",
    "    wrapped_text = textwrap.fill(chunk.text[:500]+\"...\", width=80)\n",
    "    print(textwrap.indent(wrapped_text, \"    \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536454b0-c87c-43fb-bf0c-be744732f671",
   "metadata": {},
   "source": [
    "We get a relatively \"even\" distribution of chunks here. \n",
    "\n",
    "So let's continue on with this approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d67fd35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
